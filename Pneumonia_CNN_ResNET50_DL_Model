

import os
from sklearn.metrics import f1_score, recall_score, roc_auc_score, confusion_matrix, precision_score
from PIL import Image
import numpy as np
import torch
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import OneCycleLR

##### Modified the dataset path before running #########
BASE_DIR = "/mnt/batch/tasks/shared/LS_root/mounts/clusters/rsingh9691/code/Users/rsingh969/Pneumonia_ResNet50_Assignment/chest_xray/chest_xray"

train_dir = os.path.join(BASE_DIR, "train")
val_dir   = os.path.join(BASE_DIR, "val")
test_dir  = os.path.join(BASE_DIR, "test")
########################################################

# Step 1: Define transforms including pixel clipping and normalization
class ClipAndNormalize(object):
    def __call__(self, image):
        # Convert PIL image to tensor
        image = transforms.ToTensor()(image)
        # Clip pixel values between 0 and 1 (assuming image already normalized)
        image = torch.clamp(image, 0., 1.)
        # Normalize with mean/std specific to dataset or ImageNet stats
        image = transforms.Normalize([0.485], [0.229])(image)
        return image


train_transforms = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomCrop((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(degrees=15),
    transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Optional color variations
    transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),  # Small shifts
    ClipAndNormalize()
])

test_val_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    ClipAndNormalize()
])


# Step 2: Custom dataset class with error handling for unreadable or missing files
class ImageFolderWithErrorHandling(ImageFolder):
    def __getitem__(self, index):
        path, target = self.samples[index]
        try:
            sample = self.loader(path)
            if self.transform is not None:
                sample = self.transform(sample)
            if self.target_transform is not None:
                target = self.target_transform(target)
        except Exception as e:
            print(f"Warning: Could not load image {path}. Exception: {e}")
            return None  # Signal to skip this sample
        return sample, target, path


# Step 3: Function to verify and filter out corrupt or missing files
def get_valid_samples(image_folder):
    valid_samples = []
    for path, target in image_folder.samples:
        if os.path.exists(path):
            try:
                # Verify image file integrity
                Image.open(path).verify()
                valid_samples.append((path, target))
            except Exception as e:
                print(f"Corrupt or unreadable file: {path} - {e}")
        else:
            print(f"Missing file: {path}")
    return valid_samples


# Function to load dataset with filtering corrupted/missing files
def load_dataset(data_dir, transform):
    dataset = ImageFolderWithErrorHandling(data_dir, transform=transform)
    # Filter out corrupt and missing files
    dataset.samples = get_valid_samples(dataset)
    dataset.targets = [s[1] for s in dataset.samples]  # update targets accordingly
    return dataset


# Step 4: Pixel intensity outlier detection function per dataset
def detect_intensity_outliers(dataset, threshold_std=2):
    mean_intensities = []
    for path, _ in dataset.samples:
        img = Image.open(path).convert('L')  # Grayscale
        img_tensor = transforms.ToTensor()(img)
        mean_intensities.append(img_tensor.mean().item())
    means_np = np.array(mean_intensities)
    mean_val = means_np.mean()
    std_val = means_np.std()
    outlier_indices = np.where(
        (means_np < mean_val - threshold_std * std_val) |
        (means_np > mean_val + threshold_std * std_val)
    )[0]
    return outlier_indices


# Step 5: Remove pixel intensity outliers from dataset samples
def remove_outliers(dataset, outlier_indices):
    outlier_set = set(outlier_indices)
    dataset.samples = [s for i, s in enumerate(dataset.samples) if i not in outlier_set]
    dataset.targets = [s[1] for s in dataset.samples]


# Step 6: Create WeightedRandomSampler for class imbalance in train set
def get_weighted_sampler(dataset):
    targets = [s[1] for s in dataset.samples]
    class_sample_count = torch.tensor(
        [targets.count(c) for c in range(len(dataset.classes))]
    )
    weights = 1.0 / class_sample_count.float()
    samples_weight = torch.tensor([weights[t] for t in targets])
    sampler = WeightedRandomSampler(
        weights=samples_weight,
        num_samples=len(samples_weight),
        replacement=True
    )
    return sampler


# === Load datasets ===
train_dataset = load_dataset(train_dir, train_transforms)
val_dataset = load_dataset(val_dir, test_val_transforms)
test_dataset = load_dataset(test_dir, test_val_transforms)

print(f"Original train samples: {len(train_dataset.samples)}")

# === Detect and remove pixel intensity outliers ===
train_outliers = detect_intensity_outliers(train_dataset)
print(f"Detected {len(train_outliers)} pixel intensity outliers in train set.")
remove_outliers(train_dataset, train_outliers)
print(f"Train samples after outlier removal: {len(train_dataset.samples)}")

val_outliers = detect_intensity_outliers(val_dataset)
print(f"Detected {len(val_outliers)} pixel intensity outliers in val set.")
remove_outliers(val_dataset, val_outliers)
print(f"Val samples after outlier removal: {len(val_dataset.samples)}")

test_outliers = detect_intensity_outliers(test_dataset)
print(f"Detected {len(test_outliers)} pixel intensity outliers in test set.")
remove_outliers(test_dataset, test_outliers)
print(f"Test samples after outlier removal: {len(test_dataset.samples)}")


# === Create weighted sampler for class imbalance handling (train only) ===
train_sampler = get_weighted_sampler(train_dataset)

# For val and test datasets, we do not apply sampler (use sequential sampling)
val_sampler = None
test_sampler = None


# === Optional: DataLoaders (if you want to iterate over data) ===
train_loader = DataLoader(
    train_dataset,
    batch_size=32,
    sampler=train_sampler,
    collate_fn=lambda batch: list(filter(lambda x: x is not None, batch))
)

val_loader = DataLoader(
    val_dataset,
    batch_size=32,
    shuffle=False,
    collate_fn=lambda batch: list(filter(lambda x: x is not None, batch))
)

test_loader = DataLoader(
    test_dataset,
    batch_size=32,
    shuffle=False,
    collate_fn=lambda batch: list(filter(lambda x: x is not None, batch))
)

print("Data loaders and datasets prepared.")

# === Return datasets and loaders as variables ===
# - train_dataset, val_dataset, test_dataset are filtered with missing data removed, outliers removed, ready for training
# - train_sampler implements class imbalance handling with WeightedRandomSampler

# You can now use train_dataset, val_dataset, test_dataset in your training pipeline

import torch
import torch.nn as nn
import torchvision.models as models

# Squeeze-and-Excitation (SE) block
class SEBlock(nn.Module):
    def __init__(self, channel, reduction=16):
        super(SEBlock, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )
    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)

# Stochastic Depth (Row-wise version)
class StochasticDepth(nn.Module):
    def __init__(self, p):
        super(StochasticDepth, self).__init__()
        self.p = p
    def forward(self, x, residual):
        if not self.training or self.p == 0.:
            return x + residual
        survival_rate = 1 - self.p
        size = [x.shape[0]] + [1] * (x.ndim - 1)
        noise = torch.rand(size, device=x.device, dtype=x.dtype) < survival_rate
        noise = noise.to(x.dtype) / survival_rate
        return x + residual * noise

# Depthwise separable conv
class SeparableConv2d(nn.Module):
    def __init__(self, in_ch, out_ch, kernel=3, stride=1, padding=1):
        super(SeparableConv2d, self).__init__()
        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel, stride, padding, groups=in_ch, bias=False)
        self.pointwise = nn.Conv2d(in_ch, out_ch, 1, bias=False)
    def forward(self, x):
        return self.pointwise(self.depthwise(x))

# Encoder-Decoder Model
class ResNet50_SENet_Autoencoder(nn.Module):
    def __init__(self, dropout=0.5, stochastic_depth_prob=0.1,freeze_encoder=True):
        super().__init__()
        resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)

        if freeze_encoder:
            for param in resnet.parameters():
                param.requires_grad = False

	
        self.encoder0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool,nn.Dropout2d(dropout))
        self.encoder1 = nn.Sequential(resnet.layer1,nn.Dropout2d(dropout))  # 256
        self.encoder2 = nn.Sequential(resnet.layer2,nn.Dropout2d(dropout))  # 512
        self.encoder3 = nn.Sequential(resnet.layer3,nn.Dropout2d(dropout))  # 1024
        self.encoder4 = nn.Sequential(resnet.layer4,nn.Dropout2d(dropout))  # 2048
        # SE Blocks and Stochastic Depth for each encoder layer
        self.se1 = SEBlock(256)
        self.se2 = SEBlock(512)
        self.se3 = SEBlock(1024)
        self.se4 = SEBlock(2048)
        self.sd1 = StochasticDepth(stochastic_depth_prob)
        self.sd2 = StochasticDepth(stochastic_depth_prob)
        self.sd3 = StochasticDepth(stochastic_depth_prob)
        self.sd4 = StochasticDepth(stochastic_depth_prob)
        self.dropout = nn.Dropout(dropout)
        # Decoder with upsampling (ConvTranspose), skip connections, and separable convolutions
        self.up4 = nn.ConvTranspose2d(2048, 1024, kernel_size=2, stride=2)
        self.dec4 = nn.Sequential(SeparableConv2d(1024+1024, 1024), nn.ReLU(inplace=True), nn.Dropout2d(dropout))
        self.up3 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dec3 = nn.Sequential(SeparableConv2d(512+512, 512), nn.ReLU(inplace=True), nn.Dropout2d(dropout))
        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec2 = nn.Sequential(SeparableConv2d(256+256, 256), nn.ReLU(inplace=True), nn.Dropout2d(dropout))
        self.up1 = nn.ConvTranspose2d(256, 64, kernel_size=2, stride=2)
        self.dec1 = nn.Sequential(SeparableConv2d(64+64, 64), nn.ReLU(inplace=True), nn.Dropout2d(dropout))
        self.final = nn.Conv2d(64, 1, kernel_size=1)

    def forward(self, x):
    # Encoder
        e0 = self.encoder0(x)       # Output: [N, 64, 56, 56]
        e1 = self.encoder1(e0)      # [N, 256, 56, 56]
        e2 = self.encoder2(e1)      # [N, 512, 28, 28]
        e3 = self.encoder3(e2)      # [N, 1024, 14, 14]
        e4 = self.encoder4(e3)      # [N, 2048, 7, 7]
        
        # Apply SE & Stochastic Depth as needed—example
        se1 = self.se1(self.sd1(e1, e1))
        se2 = self.se2(self.sd2(e2, e2))
        se3 = self.se3(self.sd3(e3, e3))
        se4 = self.se4(self.sd4(e4, e4))
        
        # Decoder
        d4 = self.up4(se4)  # [N, 1024, 14, 14]
        # Align e3 (skip) to d4 spatial size
        e3_ = F.interpolate(se3, size=d4.shape[2:], mode='bilinear', align_corners=False) if d4.shape[2:] != se3.shape[2:] else se3
        d4 = torch.cat([d4, e3_], dim=1)
        d4 = self.dec4(d4)
        
        d3 = self.up3(d4)  # [N, 512, 28, 28]
        e2_ = F.interpolate(se2, size=d3.shape[2:], mode='bilinear', align_corners=False) if d3.shape[2:] != se2.shape[2:] else se2
        d3 = torch.cat([d3, e2_], dim=1)
        d3 = self.dec3(d3)
        
        d2 = self.up2(d3)  # [N, 256, 56, 56]
        e1_ = F.interpolate(se1, size=d2.shape[2:], mode='bilinear', align_corners=False) if d2.shape[2:] != se1.shape[2:] else se1
        d2 = torch.cat([d2, e1_], dim=1)
        d2 = self.dec2(d2)
        
        d1 = self.up1(d2)  # [N, 64, 112, 112] — upsample to higher size, possibly
        # e0 spatial fix for last skip connection
        e0_ = F.interpolate(e0, size=d1.shape[2:], mode='bilinear', align_corners=False) if d1.shape[2:] != e0.shape[2:] else e0
        d1 = torch.cat([d1, e0_], dim=1)
        d1 = self.dec1(d1)
        
        #out = torch.sigmoid(self.final(d1))
        out = self.final(d1)
        out = out.mean(dim=[2, 3])
        return out

class EarlyStopping:
    def __init__(self, patience=7, min_delta=1e-4):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = float('inf')
        self.early_stop = False
    
    def __call__(self, val_loss):
        if val_loss < self.best_loss - self.min_delta:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True


device = 'cuda' if torch.cuda.is_available() else 'cpu'

model = ResNet50_SENet_Autoencoder(dropout=0.4, stochastic_depth_prob=0.1,freeze_encoder=True).to(device)

# === Calculate pos_weight for BCEWithLogitsLoss ===
from collections import Counter

target_counts = Counter([label for _, label in train_dataset.samples])
neg_count = target_counts.get(0, 1)  # Avoid divide by zero
pos_count = target_counts.get(1, 1)

print(f"Class distribution: 0s={neg_count}, 1s={pos_count}")

# pos_weight = (# negative / # positive)
pos_weight_tensor = torch.tensor([neg_count / pos_count], dtype=torch.float).to(device)


#criterion = nn.BCEWithLogitsLoss()
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)


# === Optimizer with L2 regularization applied only to weights ===
decay, no_decay = [], []
for name, param in model.named_parameters():
    if param.requires_grad:
        if "bias" in name or "bn" in name or "norm" in name:
            no_decay.append(param)
        else:
            decay.append(param)


optimizer = torch.optim.Adam([
    {'params': decay, 'weight_decay': 1e-3},   # L2 regularization
    {'params': no_decay, 'weight_decay': 0.0}  # No L2 for biases/bn
], lr=1e-4)

# Reduce LR when val loss plateaus

scheduler = OneCycleLR(
    optimizer,
    max_lr=5e-4,                                # You can experiment with 5e-4 or 3e-4 as well
    steps_per_epoch=len(train_loader),
    epochs=15,
    pct_start=0.3,                              # Warmup for 30% of training
    anneal_strategy='cos',
    div_factor=10.0,                            # Initial LR = max_lr / div_factor
    final_div_factor=1e4                  # Final LR = max_lr / final_div_factor
)


def calculate_accuracy(preds, labels):
    # preds: sigmoid output tensor of shape (batch_size, 1)
    # labels: tensor of shape (batch_size,)
    preds_cls = (preds >= 0.5).float()
    correct = (preds_cls.squeeze() == labels).sum()
    return correct.item() / labels.size(0)

# --- Metric calculation function ---
def calculate_metrics(preds, labels, probs=None):
    preds = preds.flatten()
    labels = labels.flatten()
    if probs is None:
        probs = preds
    accuracy = (preds == labels).sum() / len(labels)
    precision = precision_score(labels, preds, zero_division=0)
    recall = recall_score(labels, preds, zero_division=0)
    f1 = f1_score(labels, preds, zero_division=0)
    try:
        auc = roc_auc_score(labels, probs)
    except:
        auc = 0.0
    cm = confusion_matrix(labels, preds)
    tn, fp, fn, tp = cm.ravel() if cm.size==4 else (0,0,0,0)
    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0
    return float(accuracy), float(precision), float(recall), float(f1), float(auc), float(specificity), cm

# --- Track all metrics per epoch ---
history = {
    'train_loss':[], 'val_loss':[],
    'train_acc':[], 'val_acc':[],
    'train_precision':[], 'val_precision':[],
    'train_recall':[], 'val_recall':[],
    'train_f1':[], 'val_f1':[],
    'train_auc':[], 'val_auc':[],
    'val_cm':[]
}

lr_history = []
num_epochs = 15
early_stopping = EarlyStopping(patience=7)
clip_value = 1.0

for epoch in range(num_epochs):
	            # === Unfreeze encoder at epoch 5 ===
    if epoch == 5:
        print("Unfreezing encoder layers for fine-tuning...")
        for block in [model.encoder0, model.encoder1, model.encoder2, model.encoder3, model.encoder4]:
            for param in block.parameters():
                param.requires_grad = True
                # Freeze BatchNorm layers after unfreezing
        for m in model.modules():
            if isinstance(m, nn.BatchNorm2d):
                m.eval()  # Freeze running mean/var
                for param in m.parameters():
                    param.requires_grad = False
        
            # Rebuild optimizer with discriminative learning rate
        decoder_params = []
        encoder_params = []

        for name, param in model.named_parameters():
            if param.requires_grad:
                if 'encoder' in name:
                    encoder_params.append(param)
                else:
                    decoder_params.append(param)

        optimizer = torch.optim.AdamW([
            {'params': encoder_params, 'lr': 1e-5, 'weight_decay': 3e-5},
            {'params': decoder_params, 'lr': 2e-4, 'weight_decay': 5e-4}
        ])

        # === Rebuild optimizer and scheduler ===
        #optimizer = torch.optim.Adam(
        #    filter(lambda p: p.requires_grad, model.parameters()),
        #    lr=1e-5, weight_decay=1e-4
        #)
        scheduler = torch.optim.lr_scheduler.OneCycleLR(
            optimizer,
            max_lr=5e-4,
            steps_per_epoch=len(train_loader),
            epochs=num_epochs - epoch
        )


    model.train()
    running_loss = 0.0
    running_acc = 0.0
    total_train_samples = 0
    train_labels = []
    train_probs = []

    for batch in train_loader:
        batch = list(filter(lambda x: x is not None, batch))
        if len(batch) == 0:
            continue
        
        imgs, labels, _ = zip(*batch)
        imgs = torch.stack(imgs).to(device)
        labels = torch.tensor(labels).float().to(device)

        optimizer.zero_grad()
        outputs = model(imgs)

        loss = criterion(outputs, labels.unsqueeze(1))
        loss.backward()
        # --- Gradient Clipping: Add this line ---
        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)
        optimizer.step()
        scheduler.step() # step after each batch
        lr_history.append(scheduler.get_last_lr()[0])

        running_loss += loss.item() * imgs.size(0)
        running_acc += calculate_accuracy(outputs, labels) * imgs.size(0)
        total_train_samples += imgs.size(0)
        train_probs.extend(outputs.detach().cpu().numpy())
        train_labels.extend(labels.cpu().numpy())

    #epoch_train_loss = running_loss / total_train_samples
    #epoch_train_acc = running_acc / total_train_samples

    epoch_train_loss = running_loss / len(train_labels) if train_labels else float('nan')
    train_probs = np.array(train_probs).reshape(-1)
    train_preds = (train_probs >= 0.5).astype(int)
    train_labels = np.array(train_labels).reshape(-1)
    train_acc, train_prec, train_rec, train_f1, train_auc, train_spec, _ = calculate_metrics(train_preds, train_labels, train_probs)

    # --- Validation ---
    model.eval()
    val_labels = []
    val_probs = []
    running_val_loss = 0.0
    with torch.no_grad():
        for batch in val_loader:
            batch = list(filter(lambda x: x is not None, batch))
            if len(batch) == 0: continue
            imgs, labels, _ = zip(*batch)
            imgs = torch.stack(imgs).to(device)
            labels = torch.tensor(labels).float().to(device)
            outputs = model(imgs)
            loss = criterion(outputs, labels.unsqueeze(1))
            running_val_loss += loss.item() * imgs.size(0)
            val_probs.extend(outputs.cpu().numpy())
            val_labels.extend(labels.cpu().numpy())
    epoch_val_loss = running_val_loss / len(val_labels) if val_labels else float('nan')
    val_probs = np.array(val_probs).reshape(-1)
    val_preds = (val_probs >= 0.5).astype(int)
    val_labels = np.array(val_labels).reshape(-1)
    val_acc, val_prec, val_rec, val_f1, val_auc, val_spec, val_cm = calculate_metrics(val_preds, val_labels, val_probs)

    # --- Save for plotting ---
    history['train_loss'].append(epoch_train_loss)
    history['val_loss'].append(epoch_val_loss)
    history['train_acc'].append(train_acc)
    history['val_acc'].append(val_acc)
    history['train_precision'].append(train_prec)
    history['val_precision'].append(val_prec)
    history['train_recall'].append(train_rec)
    history['val_recall'].append(val_rec)
    history['train_f1'].append(train_f1)
    history['val_f1'].append(val_f1)
    history['train_auc'].append(train_auc)
    history['val_auc'].append(val_auc)
    history['val_cm'].append(val_cm)

    print(f"Epoch [{epoch+1}/{num_epochs}] "
          f"Train Loss: {epoch_train_loss:.4f}, Train Acc: {train_acc:.4f}, "
          f"Val Loss: {epoch_val_loss:.4f}, Val Acc: {val_acc:.4f}")

    # scheduler and early stopping as before
    #scheduler.step()
    #early_stopping(epoch_val_loss)
    early_stopping(val_auc)
    if early_stopping.early_stop:
        print(f"Stopping early at epoch {epoch+1}")
        break

# --- Matplotlib plots for all metrics ---
import matplotlib.pyplot as plt
epochs = range(1, len(history['train_loss']) + 1)
plt.figure(figsize=(15, 10))

plt.subplot(2, 3, 1)
plt.plot(epochs, history['train_loss'], label='Train')
plt.plot(epochs, history['val_loss'], label='Validation')
plt.title('Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(2, 3, 2)
plt.plot(epochs, history['train_acc'], label='Train')
plt.plot(epochs, history['val_acc'], label='Validation')
plt.title('Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()

plt.subplot(2, 3, 3)
plt.plot(epochs, history['train_precision'], label='Train')
plt.plot(epochs, history['val_precision'], label='Validation')
plt.title('Precision')
plt.xlabel('Epoch')
plt.ylabel('Precision')
plt.legend()

plt.subplot(2, 3, 4)
plt.plot(epochs, history['train_recall'], label='Train')
plt.plot(epochs, history['val_recall'], label='Validation')
plt.title('Recall')
plt.xlabel('Epoch')
plt.ylabel('Recall')
plt.legend()

plt.subplot(2, 3, 5)
plt.plot(epochs, history['train_f1'], label='Train')
plt.plot(epochs, history['val_f1'], label='Validation')
plt.title('F1-score')
plt.xlabel('Epoch')
plt.ylabel('F1-score')
plt.legend()

plt.subplot(2, 3, 6)
plt.plot(epochs, history['train_auc'], label='Train')
plt.plot(epochs, history['val_auc'], label='Validation')
plt.title('AUC-ROC')
plt.xlabel('Epoch')
plt.ylabel('AUC-ROC')
plt.legend()

plt.tight_layout()
plt.show()

# Plot confusion matrix of last epoch
import seaborn as sns
plt.figure(figsize=(5,4))
sns.heatmap(history['val_cm'][-1], annot=True, fmt='d', cmap='Blues')
plt.title('Validation Confusion Matrix (Last Epoch)')
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()


# === Plot learning rate curve ===

plt.figure(figsize=(10, 4))
plt.plot(lr_history)
plt.subplot(2, 3, 1)
plt.title("OneCycleLR Learning Rate Schedule")
plt.ylabel("Learning Rate")
plt.grid(True)
plt.show()

